{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load in csv data\n",
    "original_data = pd.read_csv(\"MushroomDataset\\comma_secondary_data.csv\")\n",
    "\n",
    "# determine how much data is missing from each feature\n",
    "\n",
    "missing_info = original_data.isnull().sum() / len(original_data) * 100\n",
    "\n",
    "#Can print to analyze\n",
    "#print (\"Missing data %: \\n\", missing_info)\n",
    "\n",
    "threshold = 20\n",
    "features_to_drop = missing_info[missing_info > threshold].index\n",
    "data_drop_feature = original_data.drop(columns=features_to_drop)\n",
    "\n",
    "#print (data_clean.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data shape:  (61069, 21)\n",
      "Cleaned Data Shape:  (49067, 14)\n"
     ]
    }
   ],
   "source": [
    "# Search samples for missing or incomplete data\n",
    "missing_row = data_drop_feature.isnull().sum(axis=1)\n",
    "\n",
    "# dropping samples with any missing features\n",
    "rows_to_drop = data_drop_feature[missing_row > 0].index\n",
    "data_clean = data_drop_feature.drop(index=rows_to_drop)\n",
    "\n",
    "print(\"Original Data shape: \", original_data.shape)\n",
    "print(\"Cleaned Data Shape: \", data_clean.shape)\n",
    "\n",
    "#data_clean.to_csv(\"first_cleaning.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 2016 outliers in data\n",
      "New data shape:  (47051, 14)\n",
      "class\n",
      "1    26264\n",
      "0    20787\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Dictionary to store encoding keys\n",
    "encoding_dict = defaultdict(dict)\n",
    "\n",
    "# Break down the categories\n",
    "categorical_features = ['cap-shape', 'cap-color', 'gill-attachment', 'gill-color', 'stem-color', 'ring-type', 'habitat', 'season']\n",
    "numerical_features = ['cap-diameter', 'stem-height', 'stem-width']\n",
    "boolean_features = ['does-bruise-or-bleed', 'has-ring']\n",
    "target_class = ['class']\n",
    "\n",
    "# Drop outliers\n",
    "z_threshold = 3\n",
    "z_scores = np.abs(stats.zscore(data_clean[numerical_features]))\n",
    "outliers = (z_scores > 3).any(axis=1)\n",
    "print(f'Dropping {outliers.sum()} outliers in data')\n",
    "data_clean = data_clean[~outliers]\n",
    "print(\"New data shape: \", data_clean.shape)\n",
    "\n",
    "\n",
    "# Change target from p / e to 1 / 0\n",
    "data_clean[target_class[0]] = data_clean[target_class[0]].map({'p':1, 'e':0})\n",
    "\n",
    "print(data_clean[target_class[0]].value_counts())\n",
    "\n",
    "# Convert boolean\n",
    "for feature in boolean_features:\n",
    "    data_clean[feature] = data_clean[feature].map({'t': 1, 'f': 0})\n",
    "    encoding_dict[feature] = {'t': 1, 'f': 0}\n",
    "\n",
    "    #print(data_clean[feature].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "for feature in categorical_features:\n",
    "    # Create encoding & store in dictionary\n",
    "    encoding_map = data_clean.groupby(feature)[target_class[0]].mean()\n",
    "    encoding_dict[feature] = encoding_map.to_dict()\n",
    "\n",
    "    # Apply encoding\n",
    "    data_clean[feature] = data_clean[feature].map(encoding_dict[feature])\n",
    "\n",
    "    #print(data_clean[feature].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -1.6066858441680394 \tMax: 4.589122831282251\n",
      "Min: -2.5254325803810223 \tMax: 3.868756393778493\n",
      "Min: -1.410812605571531 \tMax: 3.9286453654100812\n",
      "       cap-diameter   stem-height    stem-width\n",
      "count  4.705100e+04  4.705100e+04  4.705100e+04\n",
      "mean   2.899496e-17 -9.664988e-17 -1.111474e-16\n",
      "std    1.000011e+00  1.000011e+00  1.000011e+00\n",
      "min   -1.606686e+00 -2.525433e+00 -1.410813e+00\n",
      "25%   -7.543238e-01 -6.343677e-01 -7.445851e-01\n",
      "50%   -1.312364e-01 -1.317317e-01 -1.928090e-01\n",
      "75%    5.188245e-01  4.821434e-01  5.408846e-01\n",
      "max    4.589123e+00  3.868756e+00  3.928645e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_clean[numerical_features])\n",
    "data_clean[numerical_features] = scaler.transform(data_clean[numerical_features])\n",
    "\n",
    "# Store scaling info & add to dictionary\n",
    "scaling_info = {}\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    scaling_info[feature] = {\n",
    "         'mean': scaler.mean_[i],\n",
    "         'std': scaler.scale_[i]\n",
    "    }\n",
    "encoding_dict['scaling'] = scaling_info\n",
    "\n",
    "for feature in numerical_features:\n",
    "    min = data_clean[feature].min()\n",
    "    max = data_clean[feature].max()\n",
    "    print(f\"Min: {min} \\tMax: {max}\")\n",
    "\n",
    "\n",
    "print(data_clean[numerical_features].describe())\n",
    "\n",
    "data_clean.to_csv(\"clean_mushroom_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
